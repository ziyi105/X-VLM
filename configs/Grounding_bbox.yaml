train_file: ['/scratch/e0735461/x-vlm/dataset/refcoco']
test_file: ['data/finetune/refcoco+_val.json','data/finetune/refcoco+_test.json']

refcoco_data: '/scratch/e0735461/x-vlm/dataset/'
det_file: 'data/finetune/refcoco+/dets.json'
coco_file: '/scratch/e0735461/x-vlm/dataset/refcoco/cocos.json'
careful_hflip: False

image_root: '/scratch/e0735461/x-vlm/dataset/refcoco/images/'

## Vision Encoder
vision_config: 'configs/config_swinB_384.json'

use_clip_vit: False
#image_res: 384
#patch_size: 16

use_swin: True
image_res: 384
patch_size: 32


## Text Encoder
use_roberta: False
text_config: 'configs/config_bert.json'  # ['configs/config_bert.json', 'configs/config_roberta.json']
text_encoder: 'bert-base-uncased'  # ['data/bert-base-uncased', 'data/roberta-base']


## Training
batch_size: 20
max_tokens: 40


## Other Settings
optimizer: {opt: adamW, lr: 3e-5, weight_decay: 0.01, lr_mult: 2}
schedular: {sched: linear, lr: 3e-5, epochs: 10, num_warmup_steps: 0.1}







